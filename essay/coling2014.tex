\documentclass[11pt]{article}
\usepackage{coling2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{apacite}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Ethics in computational decision-making}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
  In this essay we examine the ethical aspects of computational decision-making.
\end{abstract}

\section{Introduction}
Computers help us make decisions every day. They recommend products for us to
buy, they correct our spelling errors and they suggest whom we should befriend
on social network sites like Facebook. But as computers become more and more
powerful and research in artificial intelligence progresses, the idea of letting
computers make the decisions that have typically been made by humans becomes
more interesting. There are already some applications for decision-making
computers, such as the bots trading on the stock market. In their paper ‘The Ethics of Artificial Intelligence’ \citeyear{bostrom2013ethics}, \citeauthor{bostrom2013ethics} argued that increasingly complex decision-making algorithms are both inevitable and desirable. 

\paragraph{But when computer AIs will make decisions that more directly affect humans}, a series of questions
arise: Will the AIs make ethical decisions? Who is to blame for a bad decision
made by an AI? Can we trust the decision-making process? This essay will argue 
for both the positive and negative aspects regarding the ethics of a computer 
based decision and present our point of view as computer science students. 
This essay will argue for both the positive and negative aspects regarding the ethics of a computer based decision and present our point of view as computer science students. 

\section{In what areas could computer-decsiosions have ethical effects?}
There are a number of applications where AI algorithms may take important decisions that directly
affect humans. For example the possibility of
a bank using a machine learning algorithm to approve or reject mortgage
applications \cite{bostrom2013ethics}. 

\paragraph{There is research into algorithms used to predict court decisions}
\cite{martin2004competing}, with algorithms predicting as much
as 70\% of the outcomes correctly \cite{Kravets2014Court} it is
conceivable to think of an algorithm taking the actual decision of court
outcomes some day in the future. When making big decisions like these, it
becomes important for the algorithm to take in ethical aspects.

\paragraph{\citeA{Chatfield2014automate} states that medical triage is a field in which automation and algorithms already play a considerable part}. Triage is how to priorities wounded or sick patience. It could be who to treat first in an emergency situation. Should one help the most critical injuered, help a child. If two lightly injuered patience could be helped simountainisly, is it better then helping one more cirtical injured? In theese areas Artificial Inteligence decision making could be applied.

\paragraph{\citeauthor{Chatfield2014automate} also writes about the car industri.} The evolution of cars has progressed nearly one hundred years. For each year the car gets safer and safer. But still millions of peoples dies in traffic each year. There is one part wich technology cant improve, the human being driving the car. This can be solved by autonomous cars. \citeauthor{elonmuskTweet} belives that when autonomous cars are safer then self-driven cars, the public may outlaw the self-driven ones. But autonomous cars is also a question of ethical decision-making. For example some school children are crossing the road and an accident is unavoidable, should the car swerve risking the drivers life or break risking the childrens life? A ethical question.

\paragraph{Even in the late stages of the human life} one could encounter machine based decision-making. In their article “Robot Be Good: A Call for Ethical Autonomous
Machines”, \citeauthor{anderson2010robot} describe a robot which
helps the elderly in various way, for example by reminding them to take their
medicine. In such a situation, the robot would have to take into consideration
the autonomy of the person in question, who maybe does not want to take their
medicine, as well as predicting the outcome if the person does not take their
medicine. Self-driving cars is also a type of artificial intelligence that will
have to take ethical decisions.

All cases above would benefit if one could make decisions based on pure facts. Wich is not possible for a human
since we always will make subjective normative assessment. But computers can base decisions on pure facts and in all areas where this is desired computer based decision making will shine, as long as they are ethical right.

\section{Responsibility}
Imagine being arrested for a crime you did not commit.
Instead of the ordinary human judge or jury, the decision-making entity is an AI
algorithm. Despite your innocence, the algorithm comes to the conclusion that
you are guilty, and so the outcome of the trial puts you in jail.

A situation like the one described above would probably feel like a kafkaesque nightmare,
where the judgment of the AI appears like the judgment of a god. Who would be to
blame for an unfair decision from an AI? This is a important problem with
computational decision-making. Would the owner of the algorithm, e.g. a company
or as in this situation a court of law, be to blame? Would the company that
delivered the algorithm be responsible, or maybe the individual programmers who
worked on the project? Or is there maybe no one but the AI itself to blame, a
prospect that may seem silly today, but may be more reasonable in a future where
AIs approach sentience in their intelligence.

\citeauthor{mcfarland2014mind} presents a similar case in their report "Mind the Gap: Can Developers of Autonomous Weapons Systems Be Liable for War Crimes". They argue that the criminal laws of today is stated in a way that they have a need for personal accountability. 


\section{How important is transparancy in a computer made decision}
Our view on why transparence is needed. How much information is enough?
Make examples of when one of us would be satisfied when...Denied to enter a nightclub by a computer, denied bankloan, not being medicaly prioritated in an acceident. 
\subsection{How much transparency must be provided to be able to trust the outcome}

\section{Machins decision can never discriminate someone... or could it?}
Humans can not in retreat to a world of pure facts, or lace subjective normative assessment. Computers can!
Our thoughts of how a computer could be used in cases where discrimination is common. For example night club bouncer. Also argue about if a machine is not fully ethical agent, he can discriminate due to the

\section{When it comes to computer-made decisions does the end justifies the means}
Discuss the troley problem. Give reasons from Consequentialism and Deontology.
What do we prefere? Use Automated ethics article.

% \section{}


% It is obvious that ethical behavior has to be encoded into these AI
% applications. How does one do this? Typical for an AI algorithm is its ability
% to deal with novel situations, situations that there is no predetermined way how
% to deal with. This makes it harder to program an AI to behave ethically; one
% cannot simply tell an AI how to act in all possible cases, but the AI would have
% to reason ethically. (fortfarande: hur?)

% And then there is the problem of
% determining what is ethical. What constitutes ethical behavior might differ a
% lot between different situations, applications and cultures. (lite olika idéer)
% We believe that, despite the hard problem of encoding ethical behavior,
% ultimately, an AI should be able to make better and more fair decisions than a
% human being typically can. While a human can easily take in many aspects into
% its decision-making and weighing complex considerations, a human is still very
% controlled by its emotions. A human can be racist or homophobic, a human may
% personally know the people involved in the decision, a human can simply have a
% bad first impression of someone. An AI, on the other hand, can be encoded to not
% take in certain aspects such as race and sexual orientation into its decision-
% making. With the right algorithms, AIs should be better decision-makers than
% humans. 

% But of course, it is not that easy. Any decision could be considered
% by someone to be unfair. Imagine being arrested for a crime you did not commit.
% Instead of the ordinary human judge or jury, the decision-making entity is an AI
% algorithm. Despite your innocence, the algorithm comes to the conclusion that
% you are guilty, and so the outcome of the trial puts you in jail.

% A situation
% like the one described above would probably feel like a kafkaesque nightmare,
% where the judgment of the AI appears like the judgment of a god. Who would be to
% blame for an unfair decision from an AI? Therein lays an important problem with
% computational decision-making. Would the owner of the algorithm, e.g. a company
% or as in this situation a court of law, be to blame? Would the company that
% delivered the algorithm be responsible, or maybe the individual programmers who
% worked on the project? Or is there maybe no one but the AI itself to blame --- a
% prospect that may seem silly today, but may be more reasonable in a future where
% AIs approach sentience in their intelligence.

% In this mess of trying to decide
% whom to blame, it could be easy for a company, or a court of law, to avoid
% taking responsibility. A decision-making algorithm can be used as a scapegoat,
% in cases where traditionally the person who had made the decision would have
% been responsible. This is a question which is important to discuss, and we
% believe that there needs to be policy handling the matter.

% An important aspect
% of decision-making algorithms is transparency. We believe that to ensure the
% fairness and correctness of a decision-making algorithm, it is important for
% both the algorithm and its decision-making process to be transparent. Algorithms
% that make decisions in for example a court of law should be published under an
% open-source license, for anyone to study and analyze. But even with open-source
% code, it can be hard to see why a certain decision was taken when it comes to AI
% algorithms. Therefore, a trace of the reasoning leading up to a decision should
% also be published together with the decision. Through transparency, we believe
% the god-like judgment of an AI could feel more human and understandable.
% Problem is, making an algorithm transparent is not always as easy as one could
% think. Methods such as machine learning and artificial neural networks are great
% for using training data to come up with new solutions, but exactly how the new
% solutions are produced is often hard to decipher. One could publish the weights
% used in an artificial neural network, or the distributions used in a machine-
% learning algorithm, without this data making much sense. (Nick Boström pratar
% om detta i The Ethics of Artificial Intelligence, bör nog skrivas om lite så
% det blir en tydligare referens). Even algorithms that are easier to understand
% would for most people seem impossible to understand. Computer illiteracy is a
% problem as it is today, but if computers also made important decisions in
% society, then computer scientists and programmers would be part of a new upper
% class in society. (kanske lite väl luddigt skrivet) If computers should be
% allowed to make important decisions in society, the decision-making process
% should not only be transparent, but also easily understandable to non-computer
% scientists.

% Despite the difficulty of encoding ethical behavior in AIs,
% assigning responsibility for the decisions taken and making the algorithms
% transparent and understandable, we believe the computational decision-making
% will prove very useful in the future. The prospect of letting unbiased
% algorithms make important decisions instead of subjective humans is exciting. By
% overcoming the aforementioned challenges, with the help of artificial
% intelligence we may one day create a society which is more fair.


% include your own bib file like this:

% \section{Translation of non-English Terms}

% It is also advised to supplement non-English characters and terms
% with appropriate transliterations and/or translations
% since not all readers understand all such characters and terms.
% Inline transliteration or translation can be represented in
% the order of: original-form transliteration ``translation''.

% \section{Length of Submission}
% \label{sec:length}

% The maximum submission length is 8 pages (A4), plus two extra pages for
% references. Authors of accepted papers will be given additional space in
% the camera-ready version to reflect space needed for changes stemming
% from reviewers comments.

% Papers that do not
% conform to the specified length and formatting requirements may be
% rejected without review.



% \section*{Acknowledgements}

% The acknowledgements should go immediately before the references.  Do
% not number the acknowledgements section. Do not include this section
% when submitting your paper for review.

% include your own bib file like this:
\bibliographystyle{apacite}
\bibliography{references}

\end{document}
